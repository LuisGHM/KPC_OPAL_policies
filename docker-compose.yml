services:
  kafka:
    image: confluentinc/cp-kafka:latest
    container_name: opal11-kafka
    environment:
      CLUSTER_ID: "manual"
      KAFKA_KRAFT_MODE: "true"
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: "broker,controller"
      KAFKA_LISTENERS: "PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka:9092,CONTROLLER://kafka:9093"
      KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka:9093"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_NUM_PARTITIONS: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_LOG_DIRS: "/var/lib/kafka/data"
    ports:
      - "9092:9092"
      - "9093:9093"
    volumes:
      - opal11_kafka_data:/var/lib/kafka/data
    command:
      - sh
      - -c
      - |
        echo "[KAFKA INIT] Esperando volume estar disponível..."
        sleep 3

        echo "[KAFKA INIT] Conteúdo do volume:"
        ls -la /var/lib/kafka/data

        if [ ! -f /var/lib/kafka/data/.formatted ]; then
          echo "[KAFKA INIT] Volume ainda não formatado, criando cluster-id..."
          CLUSTER_ID=$(kafka-storage random-uuid)
          echo "[KAFKA INIT] Gerado Cluster ID: $CLUSTER_ID"

          kafka-storage format \
            --cluster-id "$CLUSTER_ID" \
            --config /etc/kafka/kraft/server.properties \
            --ignore-formatted

          if [ $? -eq 0 ]; then
            echo "[KAFKA INIT] Kafka formatado com sucesso."
            touch /var/lib/kafka/data/.formatted
          else
            echo "[KAFKA INIT] Erro ao formatar Kafka!"
            exit 1
          fi
        else
          echo "[KAFKA INIT] Kafka já formatado, seguindo com execução."
        fi

        exec /etc/confluent/docker/run
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "localhost:9092", "--list"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - opal_net

  debezium:
    image: quay.io/debezium/connect:3.0.0.Final
    container_name: opal11-debezium
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      BOOTSTRAP_SERVERS: "kafka:9092"
      GROUP_ID: "1"
      CONFIG_STORAGE_TOPIC: "debezium_configs"
      OFFSET_STORAGE_TOPIC: "debezium_offsets"
      STATUS_STORAGE_TOPIC: "debezium_statuses"
      CONFIG_STORAGE_REPLICATION_FACTOR: 1
      OFFSET_STORAGE_REPLICATION_FACTOR: 1
      STATUS_STORAGE_REPLICATION_FACTOR: 1
    ports:
      - "8083:8083"
    networks:
      - opal_net

  opal_server:
    image: permitio/opal-server:latest
    container_name: opal11-opal_server
    environment:
      OPAL_POLICY_REPO_MAIN_BRANCH: main
      OPAL_POLICY_REPO_URL: "https://github.com/LuisGHM/KPC_OPAL_policies.git"
      OPAL_POLICY_REPO_POLLING_INTERVAL: 30
      OPAL_BROADCAST_URI: "kafka://kafka:9092"

      # ------------------- AUTH SETTINGS -------------------
      OPAL_AUTH_PROVIDER: "preshared_key"
      OPAL_SECURITY_ENABLED: "true"
      OPAL_AUTH_MASTER_TOKEN: ${OPAL_AUTH_MASTER_TOKEN}

      OPAL_LOG_FORMAT_INCLUDE_PID: "true"
      OPAL_LOG_LEVEL: DEBUG
      OPAL_KAFKA_ENABLED: "true"
      OPAL_KAFKA_BROKER: "kafka:9092"
      OPAL_KAFKA_TOPICS: "EventNotifier.public.Employees_employees,EventNotifier.public.Devices_devices"

      # Exemplo: carrega employees e devices de uma API local (pode ser Django, Flask, etc.)
      OPAL_DATA_CONFIG_SOURCES: >
        {"config":{"entries":[
        {"url":"http://host.docker.internal:8000/employees/opal-data/","topics":["policy_data"],"dst_path":"/employees"},
        {"url":"http://host.docker.internal:8000/devices/opal-data/","topics":["policy_data"],"dst_path":"/devices"}
        ]}}
      UVICORN_NUM_WORKERS: 4
    ports:
      - "7002:7002"
    networks:
      - opal_net

  opal_client:
    image: permitio/opal-client:latest
    container_name: opal11-opal_client
    environment:
      OPAL_SERVER_URL: "http://opal_server:7002"
      OPAL_LOG_FORMAT_INCLUDE_PID: "true"
      OPAL_INLINE_OPA_LOG_FORMAT: "http"
      OPAL_LOG_LEVEL: DEBUG
      # Use seu client token (se necessário). Se não for usar token no client, pode remover
      OPAL_CLIENT_TOKEN: ${OPAL_CLIENT_TOKEN}
    ports:
      - "7766:7000"
      - "8181:8181"
    depends_on:
      - opal_server
    entrypoint: ["sh", "-c", "./wait-for.sh opal_server:7002 --timeout=20 -- ./start.sh"]
    networks:
      - opal_net

  kafka_consumer:
    build: ./kafka_consumer
    container_name: opal11-kafka_consumer
    depends_on:
      - kafka
    env_file:
      - .env   # <-- isso carrega todas as variáveis do seu arquivo
    environment:
      KAFKA_BROKER: "kafka:9092"
      TOPICS: "EventNotifier.public.Employees_employees"
      OPAL_SERVER_URL: "http://opal_server:7002/data/config"
      OPAL_DATASOURCE_TOKEN: ${OPAL_DATASOURCE_TOKEN}
    networks:
      - opal_net

networks:
  opal_net:
    driver: bridge

volumes:
  opal11_kafka_data:
  pgdata: